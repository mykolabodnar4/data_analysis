{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93f49d7c-4d18-472f-a972-c9d4403851d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ee9302f3-c935-4c35-bdb6-571cde513bb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Review     label\n",
      "0   Great music service, the audio is high quality...  POSITIVE\n",
      "1   Please ignore previous negative rating. This a...  POSITIVE\n",
      "2   This pop-up \"Get the best Spotify experience o...  NEGATIVE\n",
      "3     Really buggy and terrible to use as of recently  NEGATIVE\n",
      "4   Dear Spotify why do I get songs that I didn't ...  NEGATIVE\n",
      "5   The player controls sometimes disappear for no...  NEGATIVE\n",
      "6   I love the selection and the lyrics are provid...  POSITIVE\n",
      "7   Still extremely slow when changing storage to ...  NEGATIVE\n",
      "8   It's a great app and the best mp3 music app I ...  POSITIVE\n",
      "9   I'm deleting this app, for the following reaso...  NEGATIVE\n",
      "10                    Can't play Spotify when on WiFi  NEGATIVE\n",
      "11  I had amazon premium music family package and ...  NEGATIVE\n",
      "12  Worst app always says I'm offline and never sh...  NEGATIVE\n",
      "13        i hav any music that i like it is superðŸ™Œ  POSITIVE\n",
      "14  Improve the IA to recommend songs and to find ...  POSITIVE\n",
      "15  Android user - there are loads of glitches wit...  NEGATIVE\n",
      "16  I can't listen to my DOWNLOADED playlist while...  NEGATIVE\n",
      "17  It always crashing down; unable to play and ju...  NEGATIVE\n",
      "18  I know ads are the cost to free use And yes th...  NEGATIVE\n",
      "19  This will always be my favorite platform to li...  POSITIVE\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 52702 entries, 0 to 52701\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   Review  52686 non-null  object\n",
      " 1   label   52702 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 823.6+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "reviews = pd.read_csv('./spotify_app_reviews_dataset.csv', encoding='utf8')\n",
    "print(reviews.head(20))\n",
    "print(reviews.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "563e2c71-1ec7-4089-9bcf-7f522a35eb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews['Review'] = reviews['Review'].astype(str).apply(lambda r: r.lower())\n",
    "# remove punctuation\n",
    "reviews['Review'] = reviews['Review'].apply(lambda r: r.translate(str.maketrans('', '', string.punctuation)))\n",
    "# remove noise like ðŸ™Œ\n",
    "reviews['Review'] = reviews['Review'].astype(str).apply(lambda r: re.sub('[^A-Za-z0-9 ]+', '', r))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c320fe8f-097e-4941-9104-21d54dcc6561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     great music service the audio is high quality ...\n",
       "1     please ignore previous negative rating this ap...\n",
       "2     this popup get the best spotify experience on ...\n",
       "3       really buggy and terrible to use as of recently\n",
       "4     dear spotify why do i get songs that i didnt p...\n",
       "5     the player controls sometimes disappear for no...\n",
       "6     i love the selection and the lyrics are provid...\n",
       "7     still extremely slow when changing storage to ...\n",
       "8     its a great app and the best mp3 music app i h...\n",
       "9     im deleting this app for the following reasons...\n",
       "10                       cant play spotify when on wifi\n",
       "11    i had amazon premium music family package and ...\n",
       "12    worst app always says im offline and never sho...\n",
       "13              i hav any music that i like it is super\n",
       "14    improve the ia to recommend songs and to find ...\n",
       "15    android user  there are loads of glitches with...\n",
       "16    i cant listen to my downloaded playlist while ...\n",
       "17    it always crashing down unable to play and jus...\n",
       "18    i know ads are the cost to free use and yes th...\n",
       "19    this will always be my favorite platform to li...\n",
       "Name: Review, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['Review'].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac13a1b3-1a2f-4463-87a2-22a04c38c838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NEGATIVE': 29423, 'POSITIVE': 23279})\n",
      "Counter({0: 29423, 1: 23279})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\roman.bodnar2\\AppData\\Local\\Temp\\ipykernel_37920\\1029458943.py:10: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  reviews['label'] = reviews['label'].astype(str).replace(label_map).astype(int)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "print(Counter(reviews['label']))\n",
    "\n",
    "label_map = {\n",
    "    'NEGATIVE': 0,\n",
    "    'POSITIVE': 1\n",
    "}\n",
    "\n",
    "reviews['label'] = reviews['label'].astype(str).replace(label_map).astype(int)\n",
    "print(Counter(reviews['label']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d1116e88-927d-4519-8b7e-4e6d033fb286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33728, 273) (33728,)\n",
      "(8433, 273) (8433,)\n",
      "(10541, 273) (10541,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = reviews['Review']\n",
    "y = reviews['label']\n",
    "\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(X)\n",
    "\n",
    "X_seq = tokenizer.texts_to_sequences(X)\n",
    "X_pad = pad_sequences(X_seq, padding='post')\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pad, y, test_size=0.2, random_state=17)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=17)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_val.shape, y_val.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "04207b01-32bc-42f6-b500-e26884cd5b2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m151s\u001b[0m 142ms/step - accuracy: 0.5587 - loss: 0.6878 - val_accuracy: 0.5559 - val_loss: 0.6870\n",
      "Epoch 2/5\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m152s\u001b[0m 144ms/step - accuracy: 0.5570 - loss: 0.6870 - val_accuracy: 0.5559 - val_loss: 0.6932\n",
      "Epoch 3/5\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m147s\u001b[0m 139ms/step - accuracy: 0.5537 - loss: 0.6880 - val_accuracy: 0.5559 - val_loss: 0.6869\n",
      "Epoch 4/5\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m164s\u001b[0m 156ms/step - accuracy: 0.5581 - loss: 0.6864 - val_accuracy: 0.5559 - val_loss: 0.6869\n",
      "Epoch 5/5\n",
      "\u001b[1m1054/1054\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m163s\u001b[0m 154ms/step - accuracy: 0.5598 - loss: 0.6861 - val_accuracy: 0.5559 - val_loss: 0.6869\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1  \n",
    "embedding_dim = 100\n",
    "\n",
    "simple_model = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, trainable=False),\n",
    "    layers.LSTM(129, return_sequences=True),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "simple_model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])\n",
    "history = simple_model.fit(X_train, y_train, epochs=5, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "69c150b9-de60-4ab1-8d3c-aabe44ae5228",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 48ms/step - accuracy: 0.5666 - loss: 0.6844\n",
      "Test accuracy : 0.559339702129364\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = simple_model.evaluate(X_test, y_test)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1811a7-d5c4-41f0-8dd5-ac627f8b8d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m  11/1054\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m1:28\u001b[0m 84ms/step - accuracy: 0.4898 - loss: 0.6932"
     ]
    }
   ],
   "source": [
    "embedding_dim = 50\n",
    "glove_file = './glove.6B.50d.txt'  \n",
    "embeddings_index = {}\n",
    "\n",
    "with open(glove_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        coefs = np.asarray(values[1:], dtype='float32')\n",
    "        embeddings_index[word] = coefs\n",
    "\n",
    "embedding_matrix = np.zeros((vocab_size, embedding_dim))\n",
    "\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if i < vocab_size:\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n",
    "\n",
    "\n",
    "model_pretrained = Sequential([\n",
    "    layers.Embedding(input_dim=vocab_size, output_dim=embedding_dim, weights=[embedding_matrix], trainable=False),\n",
    "    layers.LSTM(64, return_sequences=True),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.LSTM(64),\n",
    "    layers.Dense(32, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_pretrained.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history_pretrained = model_pretrained.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b2bb6fbc-3cfe-46c3-9b0e-339cb6acfbb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m330/330\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 14ms/step - accuracy: 0.5666 - loss: 0.6844\n",
      "Test accuracy : 0.559339702129364\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model_pretrained.evaluate(X_test, y_test)\n",
    "print('Test accuracy :', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acbea38d-f9e8-4439-b35f-34db39076b73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90759859-b9cd-4c51-aa71-8819caf8c5bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7b5f2-1bb7-49ba-887d-7195f9fe67fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf714cd9-67cb-4a1e-8ff6-cef003ca9b54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d22886df-0b10-476d-a1c4-b18cc2ac4d02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'unzip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!wget https://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
    "!unzip -q glove.6B.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d042a75-cda8-40cd-8379-c9fbd45e5e90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756f85f5-a9e4-46f0-a3dd-99675299c150",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77093fe6-f315-4009-9263-325572b9e953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c28dcdac-ec57-4e0b-836c-b1e9e245c7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f5bd92b7-8dd4-4fb4-95fd-7944ef02675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3b68d230-e379-4761-be32-9a59d5da3859",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters \n",
    "max_words = 10000 # max number of words to use in the vocabulary\n",
    "max_len = 100 # max length of each text (in terms of number of words)\n",
    "embedding_dim = 100 # dimension of word embeddings\n",
    "lstm_units = 64 # number of units in the LSTM layer\n",
    "num_classes = 2 # number of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "478b9de5-3642-47be-a9c9-c6fd39e7c348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize the texts and create a vocabulary\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train.to_list())\n",
    "sequences_train = tokenizer.texts_to_sequences(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f815e6a-9133-4d45-8a8a-2a5b49cf1431",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences_test = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "969c9664-1e9a-4b1b-a24d-162523ee0d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad the sequences so they all have the same length\n",
    "train_ds = pad_sequences(sequences_train, maxlen=max_len)\n",
    "test_ds = pad_sequences(sequences_test, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "584748ad-00ff-47c4-933d-43a8c9c96393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create one-hot encoded labels\n",
    "labels = [0 if x == 'NEGATIVE' else 1 for x in y_train]\n",
    "y = keras.utils.to_categorical(labels, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "90eeb819-73e2-4b81-8216-8f7f918876bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential([\n",
    "    Embedding(max_words, embedding_dim),\n",
    "    LSTM(lstm_units),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b380af48-b005-4502-a36a-16c6a7d92443",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ae1fba81-2e42-4444-b5f5-5ab50db4f6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m1122/1318\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━\u001b[0m \u001b[1m0s\u001b[0m 288us/step"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot get result() since the metric has not yet been built.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[36], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mC:\\Python312\\Lib\\site-packages\\keras\\src\\trainers\\compile_utils.py:356\u001b[0m, in \u001b[0;36mCompileMetrics.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    354\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mresult\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    355\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuilt:\n\u001b[1;32m--> 356\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    357\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get result() since the metric has not yet been built.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         )\n\u001b[0;32m    359\u001b[0m     results \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    360\u001b[0m     unique_name_counters \u001b[38;5;241m=\u001b[39m {}\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot get result() since the metric has not yet been built."
     ]
    }
   ],
   "source": [
    "history = model.fit(x=train_ds, y=y, batch_size=32, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8860ac-1b7f-486b-b086-b332e13db97e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
